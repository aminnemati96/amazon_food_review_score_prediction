{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Autoenocder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminnemati96/amazon_food_review_score_prediction/blob/main/NLP_Autoenocder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol8Gw8Mp0Iz0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b43e34e4-14a7-4aaa-c67b-866ee7b0330a"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.utils import np_utils\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras import optimizers\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, RepeatVector, Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l_-lBfNkNtR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8d6a5975-4f55-44bf-b3ee-bdd312f58426"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 9617081828405195291\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 40984969871\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 4428133777157393675\n",
            "physical_device_desc: \"device: 0, name: Quadro RTX 8000, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZdhcmfz0MLp"
      },
      "source": [
        "dataset = pd.read_csv('NLP/final.csv')\n",
        "dataset = dataset.astype({\"Text\": str, \"Score\": int})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da77xJWN0Ryh"
      },
      "source": [
        "X, y = (dataset['Text'].values, dataset['Score'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vv1AlWfO5nV"
      },
      "source": [
        "num_words=2000# dict size\n",
        "maxlen=20# length of each doc\n",
        "tokenizer = Tokenizer(num_words = num_words, split=' ')\n",
        "tokenizer.fit_on_texts(X)# extracting features\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=maxlen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmsn6_FV0kGx"
      },
      "source": [
        "embed_dim = 150\n",
        "latent_dim = 128\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHUGTpIOL3kd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1f5012bd-2a4d-4e45-fc4c-05bff943db38"
      },
      "source": [
        "encoder_inputs = Input(shape=(maxlen,), name='Encoder-Input')\n",
        "emb_layer = Embedding(num_words, embed_dim,input_length = maxlen,\n",
        "                      name='Body-Word-Embedding', mask_zero=False)\n",
        "x = emb_layer(encoder_inputs)\n",
        "state_h = LSTM(latent_dim, name='Encoder-Last-LSTM')(x)\n",
        "encoder_model = Model(inputs=encoder_inputs,\n",
        "                      outputs=state_h, name='Encoder-Model')\n",
        "seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
        "decoded = RepeatVector(maxlen)(seq2seq_encoder_out)\n",
        "decoder_LSTM = LSTM(latent_dim, return_sequences=True,\n",
        "                    name='Decoder-LSTM-before')\n",
        "decoder_LSTM_output = decoder_LSTM(decoded)\n",
        "decoder_dense = Dense(num_words, activation='softmax',\n",
        "                      name='Final-Output-Dense-before')\n",
        "decoder_outputs = decoder_dense(decoder_LSTM_output)\n",
        "seq2seq_Model = Model(encoder_inputs,decoder_outputs )\n",
        "seq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.001),\n",
        "                      loss='sparse_categorical_crossentropy')\n",
        "history = seq2seq_Model.fit(X_pad, np.expand_dims(X_pad, -1),\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=10,\n",
        "                            validation_split=0.12, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 500239 samples, validate on 68215 samples\n",
            "Epoch 1/10\n",
            "500239/500239 [==============================] - 92s 184us/sample - loss: 4.8612 - val_loss: 3.6599\n",
            "Epoch 2/10\n",
            "500239/500239 [==============================] - 87s 174us/sample - loss: 2.9755 - val_loss: 2.4649\n",
            "Epoch 3/10\n",
            "500239/500239 [==============================] - 86s 173us/sample - loss: 2.0684 - val_loss: 1.8411\n",
            "Epoch 4/10\n",
            "500239/500239 [==============================] - 86s 172us/sample - loss: 1.4498 - val_loss: 1.3092\n",
            "Epoch 5/10\n",
            "500239/500239 [==============================] - 86s 173us/sample - loss: 1.0101 - val_loss: 0.9858\n",
            "Epoch 6/10\n",
            "500239/500239 [==============================] - 86s 172us/sample - loss: 0.7257 - val_loss: 0.6269\n",
            "Epoch 7/10\n",
            "500239/500239 [==============================] - 86s 172us/sample - loss: 0.5199 - val_loss: 0.6033\n",
            "Epoch 8/10\n",
            "500239/500239 [==============================] - 85s 170us/sample - loss: 0.4018 - val_loss: 0.4407\n",
            "Epoch 9/10\n",
            "500239/500239 [==============================] - 85s 171us/sample - loss: 0.3189 - val_loss: 0.3236\n",
            "Epoch 10/10\n",
            "500239/500239 [==============================] - 86s 172us/sample - loss: 0.2602 - val_loss: 0.3847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23BCwo8oTvDt"
      },
      "source": [
        "contents = tokenizer.texts_to_sequences(X)\n",
        "contents = pad_sequences(contents, maxlen=maxlen, padding='post')\n",
        "X_encoded = encoder_model.predict(contents)\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "y = np_utils.to_categorical(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3t9AmA0U4FU"
      },
      "source": [
        "X_train, X_test, y_train, y_test = \\\n",
        "train_test_split(X_encoded, y, test_size = 0.25, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXKy3ETUZgd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b2ac3e7f-b38f-4748-b8dd-15a3dfcd7b39"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1000, kernel_initializer='random_uniform',\n",
        "                activation='relu', input_dim=128))\n",
        "model.add(Dense(1000, kernel_initializer='random_uniform',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, kernel_initializer='random_uniform',\n",
        "                activation='relu'))\n",
        "model.add(Dense(5, kernel_initializer='random_uniform',\n",
        "                activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, \n",
        "          epochs=6, batch_size=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 426340 samples\n",
            "Epoch 1/6\n",
            "426340/426340 [==============================] - 18s 41us/sample - loss: 1.0105 - accuracy: 0.6481\n",
            "Epoch 2/6\n",
            "426340/426340 [==============================] - 17s 40us/sample - loss: 0.9892 - accuracy: 0.6517\n",
            "Epoch 3/6\n",
            "426340/426340 [==============================] - 17s 40us/sample - loss: 0.9817 - accuracy: 0.6530\n",
            "Epoch 4/6\n",
            "426340/426340 [==============================] - 18s 43us/sample - loss: 0.9764 - accuracy: 0.6541\n",
            "Epoch 5/6\n",
            "426340/426340 [==============================] - 18s 42us/sample - loss: 0.9726 - accuracy: 0.6549\n",
            "Epoch 6/6\n",
            "426340/426340 [==============================] - 18s 41us/sample - loss: 0.9692 - accuracy: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1d64fcd5288>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIdPQMQ5XwZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ac4bbbb-e1f2-4522-bb39-68e31b7435c3"
      },
      "source": [
        "model.evaluate(X_test, y_test, batch_size=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "142114/142114 [==============================] - 9s 64us/sample - loss: 0.9665 - accuracy: 0.6569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.966504280455974, 0.6569092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk3zq6RxNsW0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "58bede71-a5ce-458e-cf08-25b7636936cb"
      },
      "source": [
        "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
        "y_pred = model.predict_classes(X_test)\n",
        "print(classification_report(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.31      0.37     13243\n",
            "           1       0.20      0.00      0.00      7422\n",
            "           2       0.27      0.01      0.03     10580\n",
            "           3       0.41      0.02      0.03     20068\n",
            "           4       0.67      0.98      0.80     90801\n",
            "\n",
            "    accuracy                           0.66    142114\n",
            "   macro avg       0.40      0.26      0.25    142114\n",
            "weighted avg       0.56      0.66      0.55    142114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fztsCaTJ7s0T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3345f714-a16c-4eb3-a671-8b1b1fbc4064"
      },
      "source": [
        "val_old = [0, 1, 2, 3, 4]\n",
        "val_new = [0, 0, 1, 2, 2]\n",
        "d = dict(zip(val_old, val_new))\n",
        "Y_test2 = [d.get(e, e) for e in Y_test]\n",
        "y_pred2 = [d.get(e, e) for e in y_pred]\n",
        "print(classification_report(Y_test2, y_pred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.26      0.36     20665\n",
            "           1       0.27      0.01      0.03     10580\n",
            "           2       0.82      0.98      0.89    110869\n",
            "\n",
            "    accuracy                           0.80    142114\n",
            "   macro avg       0.56      0.42      0.43    142114\n",
            "weighted avg       0.74      0.80      0.75    142114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}